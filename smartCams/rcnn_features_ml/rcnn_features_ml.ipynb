{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20005, 4096) (20005,) (20005,)\n"
     ]
    }
   ],
   "source": [
    "import cPickle as pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Grab Input Data\n",
    "training_labels_file = '../finetuning/VOC_cropped_warped_train_small.txt'\n",
    "data_files_path = '../../VOC2012/fc7_features/'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "data_files = []\n",
    "with open(training_labels_file) as f:\n",
    "    for line in f:\n",
    "        data_file, label = line.split(' ')\n",
    "        data_file = data_file.split('/')[-1].split('.')[0] + '.pi'\n",
    "        try:\n",
    "            data.append(pickle.load(open(data_files_path + data_file, 'rb')))\n",
    "            labels.append(int(label))\n",
    "            data_files.append(data_file)\n",
    "        except IOError as e:\n",
    "            pass\n",
    "data = np.squeeze(np.array(data))\n",
    "labels = np.array(labels)\n",
    "data_files = np.array(data_files)\n",
    "print data.shape, labels.shape, data_files.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16004, 4096) (4001, 4096)\n",
      "(16004,) (4001,)\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test\n",
    "num_vectors = data.shape[0]\n",
    "test_ratio = .2\n",
    "num_test = num_vectors * test_ratio\n",
    "\n",
    "indices = np.random.permutation(num_vectors)\n",
    "training_idx, test_idx = indices[num_test:], indices[:num_test]\n",
    "training_data, test_data = data[training_idx,:], data[test_idx,:]\n",
    "training_labels, test_labels = labels[training_idx,], labels[test_idx,]\n",
    "\n",
    "print training_data.shape, test_data.shape\n",
    "print training_labels.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define Classifier\n",
    "# http://scikit-learn.org/stable/modules/grid_search.html\n",
    "from sklearn import svm, neighbors, linear_model, ensemble, grid_search \n",
    "\n",
    "scoring = 'f1_weighted'\n",
    "class_weight = 'subsample' # 'subsample' (forests only), 'auto'\n",
    "\n",
    "classifier = ensemble.RandomForestClassifier(max_depth=15, class_weight=class_weight)\n",
    "# classifier = grid_search.GridSearchCV(svm.LinearSVC(class_weight=class_weight), {'C':[.01, .1, 1, 10, 100]}, scoring=scoring)\n",
    "\n",
    "# classifier = linear_model.RidgeClassifierCV()\n",
    "# classifier = linear_model.SGDClassifier()\n",
    "# classifier = ensemble.AdaBoostClassifier()\n",
    "# classifer = ensemble.GradientBoostingClassifier()\n",
    "# classifer = ensemble.ExtraTreesClassifier()\n",
    "\n",
    "## Slow\n",
    "# classifier = grid_search.GridSearchCV(svm.SVC(class_weight=class_weight), {'kernel':('linear','rbf'), 'C':[.01, .1, 1, 10, 100]}, scoring=scoring)\n",
    "# classifier = neighbors.KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.88 s, sys: 5.5 ms, total: 3.88 s\n",
      "Wall time: 3.88 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='subsample',\n",
       "            criterion='gini', max_depth=15, max_features='auto',\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Train Classifier\n",
    "classifier.fit(training_data, training_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995688577856\n",
      "[ 0.93402253  0.93953345  0.93493746]\n",
      "0.940014996251\n"
     ]
    }
   ],
   "source": [
    "# Test Classifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "predicted_labels = classifier.predict(test_data)\n",
    "print classifier.score(training_data, training_labels) # score is always accuracy\n",
    "print cross_val_score(classifier, training_data, training_labels, scoring=scoring)\n",
    "print classifier.score(test_data, test_labels) # score is always accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion Matrix\n",
      "[[12511     2     0    17     7]\n",
      " [   10   584     0     0     1]\n",
      " [    2     0   500     2     0]\n",
      " [   15     0     0  1770     4]\n",
      " [    8     0     0     1   570]]\n",
      "Test Results\n",
      "Wrong: 240 / 4001 , 0.0599850037491\n",
      "[[3094    3    1   17   15]\n",
      " [  36  103    0    4   11]\n",
      " [   4    0   88   26    0]\n",
      " [  57    2    5  388    1]\n",
      " [  44    9    0    5   88]]\n",
      "       Image Index  Predicted  Truth\n",
      "0     pict_7513.pi          0      4\n",
      "1     pict_2624.pi          3      2\n",
      "2     pict_3021.pi          0      4\n",
      "3     pict_7570.pi          3      0\n",
      "4     pict_5797.pi          0      2\n",
      "5    pict_11951.pi          0      3\n",
      "6     pict_7151.pi          0      2\n",
      "7     pict_3979.pi          0      4\n",
      "8     pict_4499.pi          0      3\n",
      "9    pict_10287.pi          0      1\n",
      "10   pict_15638.pi          1      4\n",
      "11    pict_5687.pi          4      1\n",
      "12    pict_5513.pi          1      4\n",
      "13   pict_13310.pi          0      3\n",
      "14    pict_3748.pi          3      2\n",
      "15    pict_5325.pi          3      2\n",
      "16    pict_8751.pi          3      2\n",
      "17    pict_6176.pi          0      3\n",
      "18    pict_4367.pi          3      2\n",
      "19    pict_3128.pi          0      4\n",
      "20    pict_7945.pi          3      1\n",
      "21   pict_11605.pi          4      1\n",
      "22    pict_5925.pi          0      1\n",
      "23   pict_17510.pi          4      0\n",
      "24    pict_6500.pi          4      0\n",
      "25   pict_15684.pi          0      3\n",
      "26    pict_8710.pi          4      1\n",
      "27    pict_5383.pi          0      3\n",
      "28    pict_1580.pi          0      4\n",
      "29   pict_10145.pi          0      3\n",
      "..             ...        ...    ...\n",
      "210   pict_5488.pi          4      0\n",
      "211   pict_4945.pi          3      0\n",
      "212   pict_1055.pi          3      0\n",
      "213  pict_12721.pi          3      2\n",
      "214   pict_7732.pi          3      2\n",
      "215  pict_16494.pi          0      3\n",
      "216   pict_4886.pi          0      3\n",
      "217  pict_19418.pi          3      0\n",
      "218  pict_16055.pi          0      3\n",
      "219   pict_9223.pi          0      3\n",
      "220  pict_12477.pi          1      4\n",
      "221  pict_13117.pi          0      1\n",
      "222   pict_9833.pi          0      4\n",
      "223   pict_7250.pi          0      4\n",
      "224   pict_8947.pi          0      4\n",
      "225   pict_9440.pi          0      3\n",
      "226  pict_21573.pi          4      0\n",
      "227   pict_7899.pi          0      3\n",
      "228   pict_5960.pi          0      1\n",
      "229  pict_14999.pi          0      1\n",
      "230  pict_12224.pi          0      1\n",
      "231   pict_9280.pi          0      4\n",
      "232  pict_10761.pi          0      3\n",
      "233   pict_6731.pi          0      3\n",
      "234   pict_7325.pi          0      3\n",
      "235  pict_12912.pi          0      3\n",
      "236   pict_6849.pi          0      4\n",
      "237   pict_8280.pi          1      4\n",
      "238  pict_13231.pi          0      4\n",
      "239  pict_10488.pi          0      1\n",
      "\n",
      "[240 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "from sklearn.metrics import confusion_matrix\n",
    "wrong_test_idx = np.arange(test_labels.shape[0])[predicted_labels != test_labels]\n",
    "wrong_data_files_idx = test_idx[wrong_test_idx]\n",
    "wrong_data_files = data_files[wrong_data_files_idx]\n",
    "\n",
    "wrong_predicted = predicted_labels[predicted_labels != test_labels]\n",
    "wrong_true = test_labels[predicted_labels != test_labels]\n",
    "\n",
    "# Labels 0-4 = person, bike, bus, car, motorbike\n",
    "print \"Training Confusion Matrix\"\n",
    "print confusion_matrix(training_labels, classifier.predict(training_data))\n",
    "print \"Test Results\"\n",
    "print \"Wrong:\", len(wrong_true), '/', len(test_labels), ',', float(len(wrong_true))/len(test_labels)\n",
    "print confusion_matrix(test_labels, predicted_labels)\n",
    "print pandas.DataFrame({\"Image Index\": wrong_data_files, \"Predicted\": wrong_predicted, \"Truth\": wrong_true})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Visualize Feature Importances\n",
    "# Forest/Tree Classifiers only\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importances = classifier.feature_importances_\n",
    "\n",
    "width = 0.35       # the width of the bars\n",
    "plt.subplot(211)\n",
    "plt.bar(np.arange(importances.shape[0]), importances, width, color='r')\n",
    "plt.title(\"Feature Importances of Model\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.subplot(212)\n",
    "plt.bar(np.arange(importances.shape[0]),sorted(importances), width, color='r')\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.958243002742\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Export model\n",
    "svm_classifier = grid_search.GridSearchCV(svm.LinearSVC(class_weight='auto'), {'C':[.01, .1, 1, 10, 100]}, scoring=scoring)\n",
    "svm_classifier.fit(training_data, training_labels);\n",
    "print svm_classifier.score(test_data, test_labels)\n",
    "pickle.dump(svm_classifier, open('svm_fc7_no_bg_model', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest_classifier = ensemble.RandomForestClassifier(max_depth=15, class_weight='subsampl')\n",
    "forest_classifier.fit(training_data, training_labels);\n",
    "print svm_classifier.score(test_data, test_labels)\n",
    "pickle.dump(svm_classifier, open('svm_fc7_no_bg_model', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
