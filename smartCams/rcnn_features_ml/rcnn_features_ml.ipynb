{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(909, 200) (909,) (909,)\n"
     ]
    }
   ],
   "source": [
    "import cPickle as pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Grab Input Data\n",
    "training_labels_file = '../finetuning/VOC_cropped_warped_train_small.txt'\n",
    "data_files_path = 'rcnn_features/'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "data_files = []\n",
    "with open(training_labels_file) as f:\n",
    "    for line in f:\n",
    "        data_file, label = line.split(' ')\n",
    "        data_file = data_file.split('/')[-1].split('.')[0] + '.pi'\n",
    "        try:\n",
    "            data.append(pickle.load(open(data_files_path + data_file, 'rb')))\n",
    "            labels.append(int(label))\n",
    "            data_files.append(data_file)\n",
    "        except IOError as e:\n",
    "            pass\n",
    "data = np.squeeze(np.array(data))\n",
    "labels = np.array(labels)\n",
    "data_files = np.array(data_files)\n",
    "print data.shape, labels.shape, data_files.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(728, 200) (181, 200)\n",
      "(728,) (181,)\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test\n",
    "num_vectors = data.shape[0]\n",
    "test_ratio = .2\n",
    "num_test = num_vectors * test_ratio\n",
    "\n",
    "indices = np.random.permutation(num_vectors)\n",
    "training_idx, test_idx = indices[num_test:], indices[:num_test]\n",
    "training_data, test_data = data[training_idx,:], data[test_idx,:]\n",
    "training_labels, test_labels = labels[training_idx,], labels[test_idx,]\n",
    "\n",
    "print training_data.shape, test_data.shape\n",
    "print training_labels.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define Classifier\n",
    "# http://scikit-learn.org/stable/modules/grid_search.html\n",
    "from sklearn import svm, neighbors, linear_model, ensemble, grid_search \n",
    "\n",
    "scoring = 'f1_weighted'\n",
    "# classifier = grid_search.GridSearchCV(svm.SVC(class_weight='auto'), {'kernel':('linear', 'rbf'), 'C':[.001, .01, .1, 1, 10, 100, 1000]}, scoring=scoring)\n",
    "classifier = ensemble.RandomForestClassifier(max_depth=None, class_weight='subsample')\n",
    "\n",
    "# classifier = grid_search.GridSearchCV(svm.LinearSVC(loss='l1', class_weight='auto'), {'C':[.001, .01, .1, 1, 10, 100, 1000]}, scoring=scoring)\n",
    "# classifier = linear_model.RidgeClassifierCV()\n",
    "# classifier = linear_model.SGDClassifier()\n",
    "# classifier = neighbors.KNeighborsClassifier()\n",
    "# classifer = ensemble.AdaBoostClassifier()\n",
    "# classifer = ensemble.GradientBoostingClassifier()\n",
    "# classifer = ensemble.ExtraTreesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "% time\n",
    "# Train Classifier\n",
    "classifier.fit(training_data, training_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.57237537  0.56336525  0.60028483]\n",
      "0.662983425414\n"
     ]
    }
   ],
   "source": [
    "# Test Classifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "predicted_labels = classifier.predict(test_data)\n",
    "print cross_val_score(classifier, training_data, training_labels, scoring=scoring)\n",
    "print classifier.score(test_data, test_labels) # score is always accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion Matrix\n",
      "[[484  33   0   1   0]\n",
      " [  3  32   0   0   0]\n",
      " [  4   1  27   0   0]\n",
      " [  5   1   0  95   0]\n",
      " [  2   1   0   0  39]]\n",
      "Test Results\n",
      "Wrong: 61 / 181 , 0.337016574586\n",
      "[[119   9   0   3   0]\n",
      " [ 10   0   0   0   0]\n",
      " [ 12   0   0   0   0]\n",
      " [ 20   1   2   1   0]\n",
      " [  4   0   0   0   0]]\n",
      "    Image Index  Predicted  Truth\n",
      "0   pict_551.pi          0      3\n",
      "1   pict_748.pi          2      3\n",
      "2   pict_534.pi          0      2\n",
      "3   pict_997.pi          0      3\n",
      "4   pict_670.pi          0      4\n",
      "5   pict_500.pi          1      0\n",
      "6   pict_277.pi          1      0\n",
      "7   pict_602.pi          1      0\n",
      "8   pict_712.pi          1      0\n",
      "9   pict_928.pi          0      1\n",
      "10  pict_411.pi          0      3\n",
      "11  pict_371.pi          0      3\n",
      "12  pict_558.pi          1      3\n",
      "13  pict_700.pi          0      3\n",
      "14  pict_962.pi          0      2\n",
      "15  pict_725.pi          1      0\n",
      "16  pict_987.pi          0      1\n",
      "17  pict_779.pi          0      2\n",
      "18  pict_195.pi          0      3\n",
      "19  pict_494.pi          0      3\n",
      "20  pict_514.pi          0      4\n",
      "21  pict_586.pi          0      3\n",
      "22  pict_562.pi          0      3\n",
      "23  pict_584.pi          0      1\n",
      "24   pict_47.pi          0      3\n",
      "25  pict_164.pi          0      2\n",
      "26  pict_443.pi          0      2\n",
      "27  pict_412.pi          0      3\n",
      "28   pict_33.pi          0      3\n",
      "29  pict_142.pi          0      1\n",
      "..          ...        ...    ...\n",
      "31  pict_152.pi          0      3\n",
      "32  pict_351.pi          3      0\n",
      "33  pict_269.pi          0      2\n",
      "34  pict_430.pi          3      0\n",
      "35   pict_32.pi          0      3\n",
      "36  pict_182.pi          0      1\n",
      "37  pict_161.pi          0      2\n",
      "38  pict_549.pi          0      3\n",
      "39  pict_394.pi          0      3\n",
      "40  pict_103.pi          0      1\n",
      "41  pict_851.pi          1      0\n",
      "42  pict_927.pi          0      1\n",
      "43  pict_509.pi          0      1\n",
      "44  pict_134.pi          0      2\n",
      "45  pict_421.pi          0      4\n",
      "46  pict_301.pi          1      0\n",
      "47  pict_330.pi          0      4\n",
      "48  pict_749.pi          2      3\n",
      "49   pict_40.pi          1      0\n",
      "50  pict_141.pi          0      1\n",
      "51  pict_493.pi          0      3\n",
      "52  pict_405.pi          0      1\n",
      "53  pict_193.pi          3      0\n",
      "54  pict_981.pi          0      2\n",
      "55  pict_910.pi          0      3\n",
      "56   pict_79.pi          0      2\n",
      "57  pict_636.pi          0      3\n",
      "58  pict_860.pi          0      3\n",
      "59  pict_254.pi          0      2\n",
      "60  pict_274.pi          1      0\n",
      "\n",
      "[61 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "from sklearn.metrics import confusion_matrix\n",
    "wrong_test_idx = np.arange(test_labels.shape[0])[predicted_labels != test_labels]\n",
    "wrong_data_files_idx = test_idx[wrong_test_idx]\n",
    "wrong_data_files = data_files[wrong_data_files_idx]\n",
    "\n",
    "wrong_predicted = predicted_labels[predicted_labels != test_labels]\n",
    "wrong_true = test_labels[predicted_labels != test_labels]\n",
    "\n",
    "# Labels 0-4 = person, bike, bus, car, motorbike\n",
    "print \"Training Confusion Matrix\"\n",
    "print confusion_matrix(training_labels, classifier.predict(training_data))\n",
    "print \"Test Results\"\n",
    "print \"Wrong:\", len(wrong_true), '/', len(test_labels), ',', float(len(wrong_true))/len(test_labels)\n",
    "print confusion_matrix(test_labels, predicted_labels)\n",
    "print pandas.DataFrame({\"Image Index\": wrong_data_files, \"Predicted\": wrong_predicted, \"Truth\": wrong_true})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
